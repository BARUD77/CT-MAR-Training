{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14f797cf",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be26bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from math import exp\n",
    "\n",
    "def compute_SSIM(img1, img2, data_range, window_size=11, channel=1, size_average=True, spatial_dims=2):\n",
    "    # referred from https://github.com/Po-Hsun-Su/pytorch-ssim\n",
    "    # default window_size 11\n",
    "    if len(img1.size()) == 2:\n",
    "        shape_ = img1.shape\n",
    "        img1 = img1.view(1, 1, *shape_)\n",
    "        img2 = img2.view(1, 1, *shape_)\n",
    "    window = create_window(window_size, channel, spatial_dims=spatial_dims)\n",
    "    window = window.type_as(img1)\n",
    "\n",
    "    conv_op = F.conv2d if spatial_dims == 2 else F.conv3d\n",
    "\n",
    "    mu1 = conv_op(img1, window, padding=window_size//2)\n",
    "    mu2 = conv_op(img2, window, padding=window_size//2)\n",
    "    mu1_sq, mu2_sq = mu1.pow(2), mu2.pow(2)\n",
    "    mu1_mu2 = mu1*mu2\n",
    "\n",
    "    sigma1_sq = conv_op(img1*img1, window, padding=window_size//2) - mu1_sq\n",
    "    sigma2_sq = conv_op(img2*img2, window, padding=window_size//2) - mu2_sq\n",
    "    sigma12 = conv_op(img1*img2, window, padding=window_size//2) - mu1_mu2\n",
    "\n",
    "    C1, C2 = (0.01*data_range)**2, (0.03*data_range)**2\n",
    "    #C1, C2 = 0.01**2, 0.03**2\n",
    "    ssim_map = ((2*mu1_mu2+C1)*(2*sigma12+C2)) / ((mu1_sq+mu2_sq+C1)*(sigma1_sq+sigma2_sq+C2))\n",
    "    if size_average:\n",
    "        return ssim_map.mean().item()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1).item()\n",
    "    \n",
    "def create_window(window_size, channel, spatial_dims=2):\n",
    "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    if spatial_dims == 2:\n",
    "        window = _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
    "    else:\n",
    "        window = _2D_window.expand(channel, 1, window_size, window_size, window_size).contiguous()\n",
    "    return window\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size // 2) ** 2 / float(2 * sigma ** 2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83681f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# In CTTransforms.normalize_hu()\n",
    "def normalize_hu(hu, min_hu=-1024, max_hu=3072, do_clip=False):\n",
    "    if do_clip:\n",
    "        hu = np.clip(hu, min_hu, max_hu)\n",
    "    norm_hu = (hu - min_hu) / (max_hu - min_hu)  # Normalize to [0,1]\n",
    "    return norm_hu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad072776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c44dd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14000 matching pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SSIM:   1%|▏         | 200/14000 [00:13<15:27, 14.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average SSIM over 200 pairs: 0.795919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, re, glob\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG — adjust as needed\n",
    "# -----------------------------\n",
    "MA_DIR = r\"E:\\Briya challenge data\\input\"   # artifact-affected .raw\n",
    "GT_DIR = r\"E:\\Briya challenge data\\simulated\"    # ground-truth .raw\n",
    "MASK_DIR = r\"D:\\AAPM_MAR_dataset\\body_validate\\Mask\"  # optional: metal mask .raw\n",
    "\n",
    "# Most medical RAWs are uint16; change if yours differ (e.g., np.uint8, np.float32)\n",
    "DTYPE = np.float32\n",
    "LITTLE_ENDIAN = True  # set False if your RAWs are big-endian\n",
    "# If your filenames ALWAYS carry shape suffix like ..._512x512x1, keep True.\n",
    "# Otherwise set to False and hardcode SHAPE_2D or SHAPE_3D below.\n",
    "PARSE_SHAPE_FROM_NAME = True\n",
    "# For fallback (if not parsing from name):\n",
    "SHAPE_2D = (512, 512)      # (H, W)\n",
    "SHAPE_3D = (512, 512, 1)   # (H, W, D)\n",
    "\n",
    "# SSIM options\n",
    "WINDOW_SIZE = 11\n",
    "SPATIAL_DIMS = 2           # 2 for 2D images, 3 for volumes\n",
    "CHANNELS = 1               # single-channel\n",
    "SIZE_AVERAGE = True        # True: scalar mean SSIM; False: per-image SSIM\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "shape_pat = re.compile(r\"_([0-9]+)x([0-9]+)x([0-9]+)\\.raw$\", re.IGNORECASE)\n",
    "\n",
    "def parse_shape_from_name(fname):\n",
    "    \"\"\"\n",
    "    Extract shape like _512x512x1 from the end of the filename.\n",
    "    Returns (H, W) for 2D (if D==1) or (H, W, D) for 3D.\n",
    "    \"\"\"\n",
    "    m = shape_pat.search(fname)\n",
    "    if not m:\n",
    "        return None\n",
    "    H, W, D = map(int, m.groups())\n",
    "    if D == 1:\n",
    "        return (H, W) if SPATIAL_DIMS == 2 else (H, W, D)\n",
    "    else:\n",
    "        # If you truly have 3D volumes with D>1, set SPATIAL_DIMS=3 above.\n",
    "        return (H, W, D)\n",
    "\n",
    "def load_raw(path, dtype=DTYPE, little_endian=LITTLE_ENDIAN, shape=None):\n",
    "    \"\"\"\n",
    "    Reads a .raw binary file into a NumPy array of given shape.\n",
    "    If shape is 2D: (H, W).\n",
    "    If shape is 3D: (H, W, D).\n",
    "    \"\"\"\n",
    "    dt = dtype.newbyteorder(\"<\" if little_endian else \">\")\n",
    "    data = np.fromfile(path, dtype=dt)\n",
    "    if shape is None:\n",
    "        # Fallback: use configured defaults\n",
    "        shape = SHAPE_3D if SPATIAL_DIMS == 3 else SHAPE_2D\n",
    "    expected = int(np.prod(shape))\n",
    "    if data.size != expected:\n",
    "        raise ValueError(f\"Size mismatch for {path}: got {data.size}, expected {expected} from shape={shape}\")\n",
    "    arr = data.reshape(shape)\n",
    "    return arr\n",
    "\n",
    "def to_torch(img):\n",
    "    \"\"\"\n",
    "    Convert numpy HxW or HxWxD to torch NCHW (2D) or NCDHW (3D) with N=C=1.\n",
    "    \"\"\"\n",
    "    if SPATIAL_DIMS == 2:\n",
    "        if img.ndim == 2:\n",
    "            # H, W -> N=1,C=1,H,W\n",
    "            t = torch.from_numpy(img).unsqueeze(0).unsqueeze(0)\n",
    "        elif img.ndim == 3 and img.shape[-1] == 1:\n",
    "            # H, W, 1 -> squeeze last\n",
    "            t = torch.from_numpy(img[..., 0]).unsqueeze(0).unsqueeze(0)\n",
    "        else:\n",
    "            raise ValueError(f\"Expected 2D data, got shape {img.shape}\")\n",
    "    else:\n",
    "        # 3D volume H, W, D -> N=1,C=1,D,H,W (DepthAI conv3d expects NCDHW)\n",
    "        if img.ndim != 3:\n",
    "            raise ValueError(f\"Expected 3D data, got shape {img.shape}\")\n",
    "        t = torch.from_numpy(img).permute(2,0,1).unsqueeze(0).unsqueeze(0)  # (H,W,D)->(D,H,W)->N,C,D,H,W\n",
    "    return t.float()\n",
    "\n",
    "def data_range_from_dtype(dtype, sample=None):\n",
    "    \"\"\"\n",
    "    Compute data_range for SSIM constants.\n",
    "    If integer dtype, use full-range; if float, infer from sample or use 1.0.\n",
    "    \"\"\"\n",
    "    if np.issubdtype(dtype, np.integer):\n",
    "        info = np.iinfo(dtype)\n",
    "        return float(info.max - info.min)\n",
    "    if np.issubdtype(dtype, np.floating):\n",
    "        if sample is not None:\n",
    "            m, M = float(np.min(sample)), float(np.max(sample))\n",
    "            return max(M - m, 1e-6)\n",
    "        return 1.0\n",
    "    # default\n",
    "    return 1.0\n",
    "\n",
    "def make_pair_key(path):\n",
    "    \"\"\"\n",
    "    Generate a pairing key from filename:\n",
    "    - strip folder\n",
    "    - remove 'metalart'/'nometal' marker so both sides map to the same key\n",
    "    \"\"\"\n",
    "    name = os.path.basename(path)\n",
    "    # Remove 'metalart' or 'nometal' in the body\n",
    "    for marker in ['Input_Image', 'Simulated_Image']:\n",
    "        name = name.replace(marker, '')\n",
    "    return name\n",
    "\n",
    "# -----------------------------\n",
    "# Collect files and pair MA↔GT and mask\n",
    "# -----------------------------\n",
    "ma_files = sorted(glob.glob(os.path.join(MA_DIR, \"*.raw\")))\n",
    "gt_files = sorted(glob.glob(os.path.join(GT_DIR, \"*.raw\")))\n",
    "# mask_files=sorted(glob.glob(os.path.join(MA_DIR, \"*.raw\")))\n",
    "\n",
    "ma_map = { make_pair_key(p): p for p in ma_files }\n",
    "gt_map = { make_pair_key(p): p for p in gt_files }\n",
    "# mask_map = { make_pair_key(p): p for p in mask_files }\n",
    "\n",
    "common_keys = sorted(set(ma_map.keys()) & set(gt_map.keys()))\n",
    "if len(common_keys) == 0:\n",
    "    raise RuntimeError(\"No matching MA/GT pairs found. Check filenames and pairing logic.\")\n",
    "\n",
    "print(f\"Found {len(common_keys)} matching pairs.\")\n",
    "\n",
    "# -----------------------------\n",
    "# SSIM over all pairs\n",
    "# -----------------------------\n",
    "ssim_values = []\n",
    "for idx, key in enumerate(tqdm(common_keys, desc=\"SSIM\")):\n",
    "\n",
    "    if idx>=200:\n",
    "        break\n",
    "    p_ma = ma_map[key]\n",
    "    p_gt = gt_map[key]\n",
    "    # p_mask=mask_map[key]\n",
    "\n",
    "    # # Parse or fallback to configured shape\n",
    "    # shape = parse_shape_from_name(p_ma) if PARSE_SHAPE_FROM_NAME else (SHAPE_3D if SPATIAL_DIMS==3 else SHAPE_2D)\n",
    "    # if shape is None:\n",
    "    #     # Try GT if MA didn't contain the suffix\n",
    "    #     shape = parse_shape_from_name(p_gt)\n",
    "    # if shape is None:\n",
    "    #     raise ValueError(f\"Could not parse shape from filename: {p_ma} or {p_gt}\")\n",
    "\n",
    "    ma_np = np.fromfile(p_ma, dtype=np.float32).reshape(512, 512)\n",
    "    gt_np = np.fromfile(p_gt, dtype=np.float32).reshape(512, 512)\n",
    "    # mask_np=np.fromfile(p_mask,dtype=np.float32).reshape(512,512)\n",
    "\n",
    "    # valid_mask=to_torch(1-mask_np)\n",
    "\n",
    "\n",
    "\n",
    "    # To torch (N,C,H,W) or (N,C,D,H,W)\n",
    "    ma_np = normalize_hu(ma_np, min_hu=-1024, max_hu=3072, do_clip=True)\n",
    "    gt_np = normalize_hu(gt_np, min_hu=-1024, max_hu=3072, do_clip=True)\n",
    "    ma_t = to_torch(ma_np)\n",
    "    gt_t = to_torch(gt_np)\n",
    "\n",
    "    # Decide data_range: from dtype (e.g., 65535 for uint16) or from sample if normalized\n",
    "    if np.issubdtype(DTYPE, np.integer):\n",
    "        data_range = data_range_from_dtype(DTYPE)\n",
    "    else:\n",
    "        # if you normalized to [0,1], set data_range=1.0\n",
    "        data_range = data_range_from_dtype(DTYPE, sample=gt_np)\n",
    "\n",
    "    # Ensure window on correct device/dtype inside compute_SSIM (your earlier function should do .to(device,dtype))\n",
    "    # ssim_val = compute_SSIM(\n",
    "    #     gt_t, ma_t, data_range=1.0,\n",
    "    #     window_size=WINDOW_SIZE, channel=CHANNELS,\n",
    "    #     size_average=True, spatial_dims=SPATIAL_DIMS\n",
    "    # )\n",
    "    ssim_val = ssim(\n",
    "        gt_np, ma_np, data_range=1.0\n",
    "    )\n",
    "    ssim_values.append(ssim_val)\n",
    "\n",
    "avg_ssim = float(np.mean(ssim_values))\n",
    "print(f\"\\nAverage SSIM over {len(ssim_values)} pairs: {avg_ssim:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc179662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8442495251349558,\n",
       " 0.8567595157469338,\n",
       " 0.7729889872824913,\n",
       " 0.8245272018819748,\n",
       " 0.8328836808695359,\n",
       " 0.701032812831439,\n",
       " 0.8503461224976925,\n",
       " 0.9225199643742835,\n",
       " 0.7312957572420979,\n",
       " 0.8082519189332266,\n",
       " 0.7983551847359592,\n",
       " 0.7900781002607772,\n",
       " 0.7814206684515527,\n",
       " 0.7694909208938282,\n",
       " 0.789620832927139,\n",
       " 0.9117608507317206,\n",
       " 0.7627296586821373,\n",
       " 0.8233897798807923,\n",
       " 0.771058483787407,\n",
       " 0.8365776754428165]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssim_values[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f7f120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = r\"D:\\AAPM_MAR_dataset\\body_validate\\Mask\\test_body_metalonlymask_img3_512x512x1.raw\"\n",
    "mask_np = np.fromfile(path,dtype=np.float32).reshape(512,512)\n",
    "mask_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08f95748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c7b030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# In Colab notebook\n",
    "# ma_dir = \"/content/CT-MAR-Training/data/data_npy/input/MA_image\"\n",
    "# li_dir = \"/content/CT-MAR-Training/data/data_npy/input/LI\"\n",
    "# gt_dir = \"/content/CT-MAR-Training/data/data_npy/simulated/img\"\n",
    "# config_path = \"/content/CT-MAR-Training/swin_unet/config.yaml\"\n",
    "# log_dir = \"/content/drive/MyDrive/MAR_project/runs\"\n",
    "\n",
    "ma_dir = r\"E:\\Briya challenge data\\input\"\n",
    "gt_dir = r\"E:\\Briya challenge data\\simulated\"\n",
    "config_path = r\"C:\\Khalifa University Documents\\Summer 2025\\Training\\swin_unet\\config.yaml\"\n",
    "log_dir = r\"C:\\Khalifa University Documents\\Summer 2025\\Training\\runs\"\n",
    "\n",
    "# Then inside the cell:\n",
    "!python trainer.py --model swinunet --ma_dir \"{ma_dir}\" --gt_dir \"{gt_dir}\" --config \"{config_path}\" --log_dir \"{log_dir}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuda_test)",
   "language": "python",
   "name": "cuda_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
